# Техническое решение

Третьим этапом приложите технические артефакты.

**Технические артефакты:**

# 1) Описание архитектуры решения

- ### Языки програмирования - *Python, JavaScript (JS), MySQL*; Фреймфорки - *Django, Pytorch, Llama.cpp, Node.js, pymysql*;
- ### *MySql* – база данных *s7survey.sql*. Сервер на *node.js*. *Python interpreter*, *NVIDIA-CUDA-Kernels toolkit* и драйвер. *vurtual environment*.
- ### Данные были получены из *Hugging Face* взята LLM-модель, ориентированое на определенные бенчмарки, такие как "MUSR"(Multilingual Understanding and Reasoning), "MMLU"(Massive Multitask Language Understanding), "IFEval"(Inference Evaluation) и "BBH"(Big-Bench Hard). Также были получены и обработаны датасеты иностранных отзывов об авиакомпании, которую мы нормализовали и использовали для отбора лучшей языковой модели по итоговым метрикам
- ### Языковых моделей было две - *"qwen-2.5-7b-deep-stock-v4"* и *"Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1"* расширения "gguf". Модели использовались в предобученном виде и работали по четко заданному системному и пользовательсткому промту. Имеется возможность сделать few-shot промтинг. Файн-тюнить мы не решили из за отсутвия времени и нужного вычислительной мощности. (Коллаб юзать не вариант, из за его нестабильности держать сессию) 
- ### Наше решение на базе LLM-модели обладает высоким потенциалом к масштабированию, поскольку архитектура системы позволяет адаптироваться к разным сценариям использования и объемам данных.
- ### Есть мокирование, так как нет подключение к серверам компании и нет реальных рейсов.

# 2) Инструкция по развертыванию

- ### Перечень шагов по развертыванию технического решения:
### 1) Устанавливаем все необходимые фреймворки и виртуальные среды, включая пакеты для работы с *Python, Node.js, MySQL*
### 2) Запускаем каждое решение отдельно: сначала разворачиваем *MySQL* сервер, потом языковую модель вместе с файлом, обращающимся к API-Серверу, который дает доступ к таблице БД по индексу пассажира. Запускаем сам Сервер на Node.js, и в конце запускаем сервер на Django для инициализации БД и фронтэнда с бэкэндом.
### 3) Запуск API Сервера, после установки ноды, пишем в терминале данной директории "npm init", "npm serve". Django запускается после активации venv, в файле requement.txt есть все нужные пакеты которые ставятся *"pip install -r requement.txt"*. Языковая модель работает пока что через юпитер-ноутбук как тестовая
### - Наше решение основано на LLM-модели и требует соответствующей инфраструктуры для обработки данных. Оно может быть развернуто как в облачной среде, так и локально при наличии необходимых вычислительных ресурсов.
________________________________________
#### 1. Требования к оборудованию
Облачное развертывание (рекомендуемый вариант)
Облачные провайдеры: AWS, Google Cloud, Azure, Yandex Cloud
GPU: NVIDIA GeForce RTX 4060M (не менее 6 GB VRAM)
 RAM:  до 32 GB
 Хранилище: от 500 GB SSD (для хранения данных и модели)
Процессор: Intel Core I5 12500H
Локальное развертывание
ОС: Ubuntu 20.04 / Windows 11 / macOS (M1/M2)
 GPU: NVIDIA RTX 3090 / 4090 (или аналог)
RAM: 32 GB (рекомендуется)
Хранилище: 1 TB NVMe SSD
 Docker + CUDA для оптимизации вычислений
________________________________________
#### 2. Установка необходимых компонентов
Шаг 1: Установка системных пакетов
Шаг 2: Установка и настройка Python-зависимостей
Шаг 3: Настройка GPU (если используется локально)

#### 3. Развертывание модели
Облачное развертывание (Docker + API сервер)
1.  Клонируем репозиторий с кодом
2.  Настраиваем Docker-контейнер
3.  Запуск API сервера
4. Интеграция с внутренними сервисами
5. Мониторинг и обновление

